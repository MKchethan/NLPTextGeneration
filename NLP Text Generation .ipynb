{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1c5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy import array\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d52dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '''My favourite color is black\n",
    "my favourite pet is dog\n",
    "my favourite food is upma\n",
    "my favourite flower is rose\n",
    "my favourite place is bengaluru\n",
    "my favourite outfit is formals'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d39fea37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my favourite color is black',\n",
       " 'my favourite pet is dog',\n",
       " 'my favourite food is upma',\n",
       " 'my favourite flower is rose',\n",
       " 'my favourite place is bengaluru',\n",
       " 'my favourite outfit is formals']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowering the case of every character in the sentences\n",
    "\n",
    "data = data.lower().split('\\n')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4bf88b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordIndex: {'my': 1, 'favourite': 2, 'is': 3, 'color': 4, 'black': 5, 'pet': 6, 'dog': 7, 'food': 8, 'upma': 9, 'flower': 10, 'rose': 11, 'place': 12, 'bengaluru': 13, 'outfit': 14, 'formals': 15}\n",
      "Vocabulary size: 16\n"
     ]
    }
   ],
   "source": [
    "# integer encode text\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# creates tokens for each words present in the data\n",
    "tokenizer.fit_on_texts(data)                     \n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"WordIndex:\", tokenizer.word_index)\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a99ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "\n",
    "for sentence in data:\n",
    "    token = tokenizer.texts_to_sequences([sentence])[0] #converts each sentence as its tokenized equivalent\n",
    "    for i in range(1, len(token)):\n",
    "        sequence = token[:i+1]           #generating sequences\n",
    "        input_sequences.append(sequence) #appending each sequence to the list of our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be9a958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2],\n",
       " [1, 2, 4],\n",
       " [1, 2, 4, 3],\n",
       " [1, 2, 4, 3, 5],\n",
       " [1, 2],\n",
       " [1, 2, 6],\n",
       " [1, 2, 6, 3],\n",
       " [1, 2, 6, 3, 7],\n",
       " [1, 2],\n",
       " [1, 2, 8],\n",
       " [1, 2, 8, 3],\n",
       " [1, 2, 8, 3, 9],\n",
       " [1, 2],\n",
       " [1, 2, 10],\n",
       " [1, 2, 10, 3],\n",
       " [1, 2, 10, 3, 11],\n",
       " [1, 2],\n",
       " [1, 2, 12],\n",
       " [1, 2, 12, 3],\n",
       " [1, 2, 12, 3, 13],\n",
       " [1, 2],\n",
       " [1, 2, 14],\n",
       " [1, 2, 14, 3],\n",
       " [1, 2, 14, 3, 15]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35b92c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen_sequence = max([len(x) for x in input_sequences]) #calculating the length of the longest sequence\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=maxlen_sequence, padding='pre')) #pre-pading each value of the input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4567d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  1,  2],\n",
       "       [ 0,  0,  1,  2,  4],\n",
       "       [ 0,  1,  2,  4,  3],\n",
       "       [ 1,  2,  4,  3,  5],\n",
       "       [ 0,  0,  0,  1,  2],\n",
       "       [ 0,  0,  1,  2,  6],\n",
       "       [ 0,  1,  2,  6,  3],\n",
       "       [ 1,  2,  6,  3,  7],\n",
       "       [ 0,  0,  0,  1,  2],\n",
       "       [ 0,  0,  1,  2,  8],\n",
       "       [ 0,  1,  2,  8,  3],\n",
       "       [ 1,  2,  8,  3,  9],\n",
       "       [ 0,  0,  0,  1,  2],\n",
       "       [ 0,  0,  1,  2, 10],\n",
       "       [ 0,  1,  2, 10,  3],\n",
       "       [ 1,  2, 10,  3, 11],\n",
       "       [ 0,  0,  0,  1,  2],\n",
       "       [ 0,  0,  1,  2, 12],\n",
       "       [ 0,  1,  2, 12,  3],\n",
       "       [ 1,  2, 12,  3, 13],\n",
       "       [ 0,  0,  0,  1,  2],\n",
       "       [ 0,  0,  1,  2, 14],\n",
       "       [ 0,  1,  2, 14,  3],\n",
       "       [ 1,  2, 14,  3, 15]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "250110ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting X and y values\n",
    "\n",
    "X, y = input_sequences[:,:-1],input_sequences[:,-1]   # last column is taken as label y\n",
    "\n",
    "y = to_categorical(y, num_classes=vocab_size)   # creating one hot encoding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b91a5050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b06e8e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff2259f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 64)             1024      \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 20)                1700      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                336       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,060\n",
      "Trainable params: 3,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 2.7733 - accuracy: 0.0417\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7512 - accuracy: 0.0417\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.7294 - accuracy: 0.0833\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.7078 - accuracy: 0.3750\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.6863 - accuracy: 0.3750\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6648 - accuracy: 0.3750\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6432 - accuracy: 0.4167\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.6215 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.5996 - accuracy: 0.5417\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5775 - accuracy: 0.5417\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.5550 - accuracy: 0.5833\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5323 - accuracy: 0.5833\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.5092 - accuracy: 0.5833\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.4857 - accuracy: 0.5833\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4618 - accuracy: 0.5833\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.4375 - accuracy: 0.5833\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.4128 - accuracy: 0.5833\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3876 - accuracy: 0.5833\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3620 - accuracy: 0.5833\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3359 - accuracy: 0.5833\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3094 - accuracy: 0.5833\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2825 - accuracy: 0.5833\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2551 - accuracy: 0.5833\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2273 - accuracy: 0.5833\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.1992 - accuracy: 0.5833\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1707 - accuracy: 0.5833\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1419 - accuracy: 0.5833\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1129 - accuracy: 0.5833\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0836 - accuracy: 0.5833\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0541 - accuracy: 0.5833\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0246 - accuracy: 0.5833\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9950 - accuracy: 0.5833\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9654 - accuracy: 0.5833\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9359 - accuracy: 0.5833\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9065 - accuracy: 0.5833\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8773 - accuracy: 0.5833\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8484 - accuracy: 0.5833\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8197 - accuracy: 0.5833\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7914 - accuracy: 0.5833\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7636 - accuracy: 0.5833\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7362 - accuracy: 0.5833\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7093 - accuracy: 0.5833\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6829 - accuracy: 0.6250\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6572 - accuracy: 0.6250\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6320 - accuracy: 0.6250\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6075 - accuracy: 0.6250\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5837 - accuracy: 0.6250\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5606 - accuracy: 0.6250\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5382 - accuracy: 0.6250\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5165 - accuracy: 0.6250\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4956 - accuracy: 0.6250\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4753 - accuracy: 0.6250\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4558 - accuracy: 0.6250\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4370 - accuracy: 0.6250\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4188 - accuracy: 0.6250\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4014 - accuracy: 0.6250\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3846 - accuracy: 0.6250\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3684 - accuracy: 0.6250\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3528 - accuracy: 0.6250\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3378 - accuracy: 0.6250\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3234 - accuracy: 0.6250\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3095 - accuracy: 0.5833\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2962 - accuracy: 0.5833\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2833 - accuracy: 0.5833\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2708 - accuracy: 0.5833\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2589 - accuracy: 0.5833\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2473 - accuracy: 0.5833\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2361 - accuracy: 0.6250\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2253 - accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2149 - accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2048 - accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1951 - accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1856 - accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1765 - accuracy: 0.6667\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1676 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1590 - accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1506 - accuracy: 0.6667\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1425 - accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1346 - accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1270 - accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1195 - accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1122 - accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1051 - accuracy: 0.7083\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0981 - accuracy: 0.7083\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0914 - accuracy: 0.7083\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0847 - accuracy: 0.7083\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0783 - accuracy: 0.7083\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0719 - accuracy: 0.7083\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0657 - accuracy: 0.7083\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0596 - accuracy: 0.7083\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0536 - accuracy: 0.7083\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0477 - accuracy: 0.7083\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0419 - accuracy: 0.7083\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0362 - accuracy: 0.7083\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0305 - accuracy: 0.7083\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0250 - accuracy: 0.7083\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0195 - accuracy: 0.7083\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0140 - accuracy: 0.7083\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.7083\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0033 - accuracy: 0.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200c0f34a00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building\n",
    "model = Sequential()  # creating sequential model\n",
    "model.add(Embedding(vocab_size, 64, input_length=4))  # adding embedding layer \n",
    "model.add(SimpleRNN(20))  # add SimpleRNN layer with 20 units \n",
    "model.add(Dense(vocab_size, activation='softmax'))  # adding dense layer \n",
    "print(model.summary())\n",
    "\n",
    "# Compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19eb2a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from the model\n",
    "def generate_seq(model, tokenizer, enter_text, n_pred):  \n",
    "    in_text, result = enter_text, enter_text\n",
    "    # generate a fixed number of words\n",
    "    for i in range(n_pred):\n",
    "\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=maxlen_sequence-1, padding='pre') #padding the input_phrase\n",
    "\n",
    "\n",
    "        # predict a word in the vocabulary\n",
    "\n",
    "        yhat = np.argmax(model.predict(encoded), axis=-1)\n",
    "\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text, result = out_word, result + ' ' + out_word\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27b2c00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my favourite place is bengaluru\n"
     ]
    }
   ],
   "source": [
    "# To evaluate\n",
    "# 'my fav place' --> input text\n",
    "# '1' --> generating of 1 number of word\n",
    "\n",
    "print(generate_seq(model, tokenizer, 'my favourite place is', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7b7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f04c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd7148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
